{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyfMmMnPJjvn",
        "colab_type": "text"
      },
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjcGOJhcJjvp",
        "colab_type": "text"
      },
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0Pl2XjJjvq",
        "colab_type": "text"
      },
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tjeebg4N9L8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "e2f057cd-b136-4b13-b392-b1541725e7f4"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import cifar10, mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr75v_UYJjvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "80566960-f7b0-4bdc-be72-f7e3d41de6d9"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 4us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTI42-0qJjvw",
        "colab_type": "text"
      },
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2sf67VoJjvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e767a04c-a5a4-447a-a9cc-d11b5cc0535d"
      },
      "source": [
        "print('--- THE DATA ---')\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- THE DATA ---\n",
            "x_train shape: (60000, 28, 28)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zewyDcBlJjv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d61f6217-d927-4594-de55-9c1574d6fedc"
      },
      "source": [
        "\"\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WytT2eRnJjv4",
        "colab_type": "text"
      },
      "source": [
        "### Find dimensions of an image in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XycQGBSGJjv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "6f687aab-a196-4316-df69-4296676fb8cf"
      },
      "source": [
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jtdZ7RqJjv8",
        "colab_type": "text"
      },
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO8yGYoQREJD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cb5ca801-af41-4e94-bb7f-730da70d385f"
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAD3q5I6Jjv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "num_classes = 10\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgHSCXy3JjwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da5-DwgrJjwM",
        "colab_type": "text"
      },
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okwo_SB5JjwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO5BRBzBJjwD",
        "colab_type": "text"
      },
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fUQpMHxJjwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPGVQ-JJJjwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRRTJq8JjwQ",
        "colab_type": "text"
      },
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWTZYnKSJjwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## All imports are in first Line"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C18AoS7eJjwU",
        "colab_type": "text"
      },
      "source": [
        "### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DORCLgSwJjwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "186705ad-ad18-4ae7-ed8d-f08b18fdf048"
      },
      "source": [
        "TRAIN = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "\n",
        "\n",
        "# Define model\n",
        "model1 = Sequential()\n",
        "\n",
        "# 1st Conv Layer\n",
        "model1.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "model1.add(Activation('relu'))\n",
        "\n",
        "# 2nd Conv Layer\n",
        "model1.add(Convolution2D(32, 3, 3))\n",
        "model1.add(Activation('relu'))\n",
        "\n",
        "# Fully Connected Layer\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(128))\n",
        "model1.add(Activation('relu'))\n",
        "\n",
        "# Prediction Layer\n",
        "model1.add(Dense(10))\n",
        "model1.add(Activation('softmax'))\n",
        "\n",
        "# Loss and Optimizer\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Store Training Results\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
        "callback_list = [early_stopping]\n",
        "\n",
        "# Train the model1\n",
        "model1.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
        "          validation_data=(x_test, y_test), callbacks=callback_list)\n",
        "    \n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 28s 463us/step - loss: 0.3705 - acc: 0.8660 - val_loss: 0.3022 - val_acc: 0.8885\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.2262 - acc: 0.9170 - val_loss: 0.2494 - val_acc: 0.9073\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.1614 - acc: 0.9392 - val_loss: 0.2666 - val_acc: 0.9105\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.1119 - acc: 0.9587 - val_loss: 0.2826 - val_acc: 0.9151\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0734 - acc: 0.9734 - val_loss: 0.3221 - val_acc: 0.9138\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.0464 - acc: 0.9836 - val_loss: 0.3508 - val_acc: 0.9155\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0353 - acc: 0.9881 - val_loss: 0.4261 - val_acc: 0.9146\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.0244 - acc: 0.9913 - val_loss: 0.4701 - val_acc: 0.9063\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 14s 233us/step - loss: 0.0219 - acc: 0.9923 - val_loss: 0.4767 - val_acc: 0.9125\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0173 - acc: 0.9941 - val_loss: 0.5102 - val_acc: 0.9116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe783e70c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju69vKdIJjwX",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2hAP94vJjwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "4e863891-f45f-46f2-8a52-8fe1d9bad145"
      },
      "source": [
        "TRAIN = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "\n",
        "\n",
        "# Define model\n",
        "model2 = Sequential()\n",
        "\n",
        "# 1st Conv Layer\n",
        "model2.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "model2.add(Activation('relu'))\n",
        "\n",
        "# 2nd Conv Layer\n",
        "model2.add(Convolution2D(32, 3, 3))\n",
        "model2.add(Activation('relu'))\n",
        "\n",
        "#Add a MaxPooling Layer of size 2X2 \n",
        "model2.add(MaxPooling2D(pool_size=(2, 2),name='max_1'))\n",
        "\n",
        "#Apply Dropout with 0.25 probability \n",
        "model2.add(Dropout(0.25,name='drop_1'))\n",
        "\n",
        "# Fully Connected Layer\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(128))\n",
        "model2.add(Activation('relu'))\n",
        "\n",
        "# Prediction Layer\n",
        "model2.add(Dense(10))\n",
        "model2.add(Activation('softmax'))\n",
        "\n",
        "# Loss and Optimizer\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Store Training Results\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
        "callback_list = [early_stopping]\n",
        "\n",
        "# Train the model2\n",
        "model2.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
        "          validation_data=(x_test, y_test), callbacks=callback_list)\n",
        "    \n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.3943 - acc: 0.8577 - val_loss: 0.3017 - val_acc: 0.8884\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.2558 - acc: 0.9071 - val_loss: 0.2460 - val_acc: 0.9090\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 0.2081 - acc: 0.9231 - val_loss: 0.2341 - val_acc: 0.9128\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 0.1750 - acc: 0.9359 - val_loss: 0.2228 - val_acc: 0.9184\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.1459 - acc: 0.9450 - val_loss: 0.2311 - val_acc: 0.9204\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.1242 - acc: 0.9533 - val_loss: 0.2364 - val_acc: 0.9220\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.1028 - acc: 0.9613 - val_loss: 0.2301 - val_acc: 0.9242\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 0.0888 - acc: 0.9666 - val_loss: 0.2799 - val_acc: 0.9196\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 0.0757 - acc: 0.9717 - val_loss: 0.2670 - val_acc: 0.9223\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 0.0668 - acc: 0.9748 - val_loss: 0.2755 - val_acc: 0.9253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe776319940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGTA3bfEJjwa",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6gX8n5SJjwb",
        "colab_type": "text"
      },
      "source": [
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbz4uHBuJjwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=False,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "\n",
        "# Prepare the generator\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl-8dOo7Jjwf",
        "colab_type": "text"
      },
      "source": [
        "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DpI1_McYJjwg",
        "colab_type": "code",
        "outputId": "1169efba-5b76-427d-b6b4-2b28fdca35c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRKJB/B+NQ7jtPkeKlQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmPl5yE8Jjwm",
        "colab_type": "text"
      },
      "source": [
        "### Run the above model using fit_generator()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ZnDdJYJjwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "outputId": "31b0c0d4-b99d-4817-9be4-faac45424ca2"
      },
      "source": [
        "model2.fit_generator(datagen.flow(x_train, y_train,batch_size=32),\n",
        "                    samples_per_epoch=x_train.shape[0],\n",
        "                    nb_epoch=20,\n",
        "                    validation_data=(x_test, y_test), callbacks=callback_list)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "  19/1875 [..............................] - ETA: 18s - loss: 2.6388 - acc: 0.2895"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1875, epochs=20)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.9347 - acc: 0.6579 - val_loss: 0.4691 - val_acc: 0.8257\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.6944 - acc: 0.7420 - val_loss: 0.4790 - val_acc: 0.8270\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.6331 - acc: 0.7664 - val_loss: 0.4785 - val_acc: 0.8228\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.5896 - acc: 0.7823 - val_loss: 0.4629 - val_acc: 0.8338\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.5582 - acc: 0.7936 - val_loss: 0.4454 - val_acc: 0.8363\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.5387 - acc: 0.8022 - val_loss: 0.4656 - val_acc: 0.8398\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.5220 - acc: 0.8080 - val_loss: 0.4294 - val_acc: 0.8431\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.5088 - acc: 0.8127 - val_loss: 0.4154 - val_acc: 0.8471\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4949 - acc: 0.8186 - val_loss: 0.4235 - val_acc: 0.8518\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4814 - acc: 0.8227 - val_loss: 0.3945 - val_acc: 0.8570\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4726 - acc: 0.8255 - val_loss: 0.4051 - val_acc: 0.8571\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.4673 - acc: 0.8289 - val_loss: 0.4468 - val_acc: 0.8436\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4622 - acc: 0.8301 - val_loss: 0.4208 - val_acc: 0.8548\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4586 - acc: 0.8305 - val_loss: 0.3652 - val_acc: 0.8707\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4524 - acc: 0.8339 - val_loss: 0.3831 - val_acc: 0.8661\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4445 - acc: 0.8372 - val_loss: 0.3817 - val_acc: 0.8620\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4403 - acc: 0.8379 - val_loss: 0.3998 - val_acc: 0.8571\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4366 - acc: 0.8390 - val_loss: 0.3867 - val_acc: 0.8635\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4352 - acc: 0.8411 - val_loss: 0.3756 - val_acc: 0.8639\n",
            "Epoch 00019: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe776450748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQQW5iOJjwq",
        "colab_type": "text"
      },
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1SrtBEPJjwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "09181347-e925-4270-a794-2c85fb5f7e67"
      },
      "source": [
        "loss_and_metrics = model2.evaluate(x_train, y_train)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 54us/step\n",
            "[0.3318512812336286, 0.8776166666666667]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBwVWNQC2qZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KXqmUDW2rM1",
        "colab_type": "text"
      },
      "source": [
        "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mja6OgQ3L18",
        "colab_type": "text"
      },
      "source": [
        "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HzVTPUM3WZJ",
        "colab_type": "text"
      },
      "source": [
        "### **Import neessary libraries for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPM558TX4KMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6hicLwP4SqY",
        "colab_type": "text"
      },
      "source": [
        "### **Load CIFAR10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ1WzrXd4WNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Pht1ggHuiT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5980b5c4-432d-4c7b-80a1-2e195e711314"
      },
      "source": [
        "(x_train_cifar, y_train_cifar), (x_test_cifar, y_test_cifar) = cifar10.load_data()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n28ccU6Hp6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "88b9c44c-9233-4e22-d98a-6df11ca5ee12"
      },
      "source": [
        "print('--- THE DATA ---')\n",
        "print('x_train shape:', x_train_cifar.shape)\n",
        "print(x_train_cifar.shape[0], 'train samples')\n",
        "print(x_test_cifar.shape[0], 'test samples')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- THE DATA ---\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IwfFBFLhuym",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "3da9a826-6325-4abe-b37f-6c34538d2ff2"
      },
      "source": [
        "\n",
        "print(x_train_cifar.shape)\n",
        "print(y_train_cifar.shape)\n",
        "print(x_test_cifar.shape)\n",
        "print(y_test_cifar.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBb1PCVHhulV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.unique(y_train_cifar)\n",
        "\n",
        "\n",
        "import keras\n",
        "num_classes = 10\n",
        "# convert class vectors to binary class matrices\n",
        "y_train_c = keras.utils.to_categorical(y_train_cifar, num_classes)\n",
        "y_test_c = keras.utils.to_categorical(y_test_cifar, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twFilUtthu-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# x_train_c = x_train_cifar.reshape(x_train_cifar.shape[0], 32, 32, 1).astype('float32')\n",
        "# x_test_c = x_test_cifar.reshape(x_test_cifar.shape[0], 32, 32, 1).astype('float32')\n",
        "\n",
        "\n",
        "x_train_cifar = x_train_cifar.astype('float32')\n",
        "x_test_cifar = x_test_cifar.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft5-cq4MhvIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_cifar /= 255\n",
        "x_test_cifar /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN3vYYhK4W0u",
        "colab_type": "text"
      },
      "source": [
        "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbekTKi4cmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen2 = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=True)  # randomly flip images\n",
        "\n",
        "# Prepare the generator\n",
        "datagen2.fit(x_train_cifar)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-SLtUhC4dK2",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare/fit the generator.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYyF-P8O4jQ8",
        "colab_type": "text"
      },
      "source": [
        "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXug4z234mwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "870e61ef-e674-445c-d88e-7e674f399ab3"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen2 = datagen2.flow(x_train_cifar[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen2.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}