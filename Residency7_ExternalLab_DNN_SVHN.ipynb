{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Residency7-ExternalLab-DNN-SVHN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeFE8PwkzUyr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "68b317f7-87dd-4323-c207-a28218b2f411"
      },
      "source": [
        "from google.colab import drive\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape, BatchNormalization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4RyEozd2mNy",
        "colab_type": "code",
        "outputId": "e5d700f0-cee3-411d-90e9-b753577e91e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqkFv1cI2mYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "# os.listdir('./drive/My Drive/AIML/great-learning/Residency-7/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7B4O3Bw2miM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# os.chdir('./drive/My Drive/AIML/great-learning/Residency-7/')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw8GRoyY3Zgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pwd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJi6Rrc-3faK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ylofu28A4Mcf",
        "colab_type": "text"
      },
      "source": [
        "# **Data fetching and understand the train/test splits. (5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG4lipLKz-kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the data set\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "# Open the file as readonly. The file should be present inside a directory called \"data\" in the same folder as code\n",
        "h5f = h5py.File('./drive/My Drive/AIML/great-learning/Residency-7/SVHN_single_grey1.h5', 'r')\n",
        "\n",
        "# Load the training, test and validation set\n",
        "x_train = h5f['X_train'][:]\n",
        "y_train = h5f['y_train'][:]\n",
        "x_test = h5f['X_test'][:]\n",
        "y_test = h5f['y_test'][:]\n",
        "\n",
        "\n",
        "# Close this file\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNuioJoU3oWl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5cf02e85-c4db-4bb5-c4d0-1ec0a6e04947"
      },
      "source": [
        "print(\"x_train shape\", x_train.shape)\n",
        "print(\"x_test shape\", x_test.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"y_test shape\", y_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape (42000, 32, 32)\n",
            "x_test shape (18000, 32, 32)\n",
            "y_train shape (42000,)\n",
            "y_test shape (18000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWme0h3746j9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f33530e9-92ee-4f82-d51e-381eeab27847"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 6 7 ... 7 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBOXGvwk5rru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (x_train, x_val, y_train, y_val) = train_test_split(x_train, y_train,test_size=0.1, random_state=10)\n",
        "# print(x_train.shape)\n",
        "# print(x_val.shape)\n",
        "# print(y_train.shape)\n",
        "# print(y_val.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1loXwmGtAcn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f22e080f-04f6-4704-8239-9dcfebbffaf6"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 32, 32, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 32, 32, 1).astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "print('--- THE DATA ---')\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- THE DATA ---\n",
            "x_train shape: (42000, 32, 32, 1)\n",
            "42000 train samples\n",
            "18000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiHbelokCXzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "EPOCHS = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNl0SvOZCbTQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "794c452d-65db-4d12-92bc-8b5cb84d26e2"
      },
      "source": [
        "    from keras.layers import LeakyReLU\n",
        "    # Define the Type of Model\n",
        "    model = Sequential()\n",
        "\n",
        "\n",
        "    # Flatten Imgaes to Vector\n",
        "    model.add(Reshape((1024,), input_shape=(32, 32, 1)))\n",
        "\n",
        "    # Layer 1\n",
        "    model.add(Dense(output_dim=2048, init='he_normal', bias=True))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    #Layer 1\n",
        "    model.add(Dense(output_dim=1024, init='he_normal', bias=True))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Layer 2\n",
        "    model.add(Dense(output_dim=10, init='he_normal', bias=True))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    ## Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]# [stats, early_stopping]\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train, nb_epoch=EPOCHS, batch_size=BATCH_SIZE,\n",
        "              validation_data=(x_test, y_test), verbose=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=2048, kernel_initializer=\"he_normal\", use_bias=True)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1024, kernel_initializer=\"he_normal\", use_bias=True)`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10, kernel_initializer=\"he_normal\", use_bias=True)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 42000 samples, validate on 18000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "42000/42000 [==============================] - 31s 733us/step - loss: 2.3615 - acc: 0.1236 - val_loss: 2.1805 - val_acc: 0.2118\n",
            "Epoch 2/20\n",
            "42000/42000 [==============================] - 30s 710us/step - loss: 1.7684 - acc: 0.3855 - val_loss: 1.4855 - val_acc: 0.5046\n",
            "Epoch 3/20\n",
            "42000/42000 [==============================] - 30s 717us/step - loss: 1.3175 - acc: 0.5732 - val_loss: 1.1692 - val_acc: 0.6255\n",
            "Epoch 4/20\n",
            "42000/42000 [==============================] - 30s 723us/step - loss: 1.1659 - acc: 0.6311 - val_loss: 1.1302 - val_acc: 0.6377\n",
            "Epoch 5/20\n",
            "42000/42000 [==============================] - 31s 728us/step - loss: 1.0795 - acc: 0.6607 - val_loss: 1.0486 - val_acc: 0.6671\n",
            "Epoch 6/20\n",
            "42000/42000 [==============================] - 30s 725us/step - loss: 1.0186 - acc: 0.6836 - val_loss: 1.1175 - val_acc: 0.6456\n",
            "Epoch 7/20\n",
            "42000/42000 [==============================] - 30s 722us/step - loss: 1.0012 - acc: 0.6897 - val_loss: 0.9322 - val_acc: 0.7154\n",
            "Epoch 8/20\n",
            "42000/42000 [==============================] - 30s 719us/step - loss: 0.9580 - acc: 0.7023 - val_loss: 0.8815 - val_acc: 0.7319\n",
            "Epoch 9/20\n",
            "42000/42000 [==============================] - 30s 722us/step - loss: 0.9207 - acc: 0.7128 - val_loss: 0.8639 - val_acc: 0.7365\n",
            "Epoch 10/20\n",
            "42000/42000 [==============================] - 30s 722us/step - loss: 0.9089 - acc: 0.7181 - val_loss: 0.8163 - val_acc: 0.7564\n",
            "Epoch 11/20\n",
            "42000/42000 [==============================] - 30s 722us/step - loss: 0.8836 - acc: 0.7261 - val_loss: 0.8469 - val_acc: 0.7413\n",
            "Epoch 12/20\n",
            "42000/42000 [==============================] - 30s 717us/step - loss: 0.8411 - acc: 0.7382 - val_loss: 0.8414 - val_acc: 0.7442\n",
            "Epoch 13/20\n",
            "42000/42000 [==============================] - 30s 714us/step - loss: 0.8374 - acc: 0.7409 - val_loss: 0.8923 - val_acc: 0.7202\n",
            "Epoch 14/20\n",
            "42000/42000 [==============================] - 30s 708us/step - loss: 0.8264 - acc: 0.7452 - val_loss: 0.7819 - val_acc: 0.7648\n",
            "Epoch 15/20\n",
            "42000/42000 [==============================] - 30s 706us/step - loss: 0.8021 - acc: 0.7526 - val_loss: 0.7619 - val_acc: 0.7719\n",
            "Epoch 16/20\n",
            "42000/42000 [==============================] - 30s 710us/step - loss: 0.8023 - acc: 0.7538 - val_loss: 0.8189 - val_acc: 0.7478\n",
            "Epoch 17/20\n",
            "42000/42000 [==============================] - 30s 708us/step - loss: 0.7744 - acc: 0.7618 - val_loss: 0.7262 - val_acc: 0.7840\n",
            "Epoch 18/20\n",
            "42000/42000 [==============================] - 30s 707us/step - loss: 0.7641 - acc: 0.7650 - val_loss: 0.7900 - val_acc: 0.7607\n",
            "Epoch 19/20\n",
            "42000/42000 [==============================] - 30s 706us/step - loss: 0.7843 - acc: 0.7592 - val_loss: 0.9136 - val_acc: 0.7279\n",
            "Epoch 20/20\n",
            "42000/42000 [==============================] - 30s 704us/step - loss: 0.7617 - acc: 0.7632 - val_loss: 0.7450 - val_acc: 0.7807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff4657f5940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDMv_rYkIIl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b4b3cacb-b142-490d-fd2a-34fc90c77a5c"
      },
      "source": [
        "loss_and_metrics = model.evaluate(x_test, y_test)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18000/18000 [==============================] - 5s 267us/step\n",
            "[0.7450011827150981, 0.7806666666666666]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlTFz5xcPQDy",
        "colab_type": "text"
      },
      "source": [
        "# **DNN Using Batch Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIu63Iy0Psp2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "d17defda-e5bf-4be7-c2ab-7e6dbeef2966"
      },
      "source": [
        "    from keras.layers import LeakyReLU\n",
        "    # Define the Type of Model\n",
        "    model_2 = Sequential()\n",
        "\n",
        "\n",
        "    # Flatten Imgaes to Vector\n",
        "    model_2.add(Reshape((1024,), input_shape=(32, 32, 1)))\n",
        "\n",
        "    # Layer 1\n",
        "    model_2.add(Dense(output_dim=2048, init='he_normal', bias=False))\n",
        "    model_2.add(BatchNormalization())\n",
        "    model_2.add(Activation(\"relu\"))\n",
        "    model_2.add(Dropout(0.2))\n",
        "    \n",
        "    #Layer 1\n",
        "    model_2.add(Dense(output_dim=1024, init='he_normal', bias=False))\n",
        "    model_2.add(BatchNormalization())\n",
        "    model_2.add(Activation(\"relu\"))\n",
        "    model_2.add(Dropout(0.2))\n",
        "\n",
        "    # Layer 2\n",
        "    model_2.add(Dense(output_dim=10, init='he_normal', bias=False))\n",
        "    model_2.add(BatchNormalization())\n",
        "    model_2.add(Activation(\"softmax\"))\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    ## Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]# [stats, early_stopping]\n",
        "\n",
        "    # Train the model\n",
        "    model_2.fit(x_train, y_train, nb_epoch=EPOCHS, batch_size=BATCH_SIZE,\n",
        "              validation_data=(x_test, y_test), verbose=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=2048, kernel_initializer=\"he_normal\", use_bias=False)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1024, kernel_initializer=\"he_normal\", use_bias=False)`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10, kernel_initializer=\"he_normal\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 18000 samples\n",
            "Epoch 1/20\n",
            "42000/42000 [==============================] - 33s 777us/step - loss: 1.4188 - acc: 0.5764 - val_loss: 1.6928 - val_acc: 0.4387\n",
            "Epoch 2/20\n",
            "42000/42000 [==============================] - 32s 752us/step - loss: 1.0141 - acc: 0.7249 - val_loss: 1.7476 - val_acc: 0.4471\n",
            "Epoch 3/20\n",
            "42000/42000 [==============================] - 32s 753us/step - loss: 0.8831 - acc: 0.7590 - val_loss: 1.4874 - val_acc: 0.5337\n",
            "Epoch 4/20\n",
            "42000/42000 [==============================] - 31s 748us/step - loss: 0.7810 - acc: 0.7847 - val_loss: 1.4690 - val_acc: 0.5404\n",
            "Epoch 5/20\n",
            "42000/42000 [==============================] - 31s 744us/step - loss: 0.7318 - acc: 0.7940 - val_loss: 1.4078 - val_acc: 0.5473\n",
            "Epoch 6/20\n",
            "42000/42000 [==============================] - 31s 746us/step - loss: 0.6775 - acc: 0.8062 - val_loss: 1.3452 - val_acc: 0.5551\n",
            "Epoch 7/20\n",
            "42000/42000 [==============================] - 31s 741us/step - loss: 0.6120 - acc: 0.8262 - val_loss: 1.2539 - val_acc: 0.5988\n",
            "Epoch 8/20\n",
            "42000/42000 [==============================] - 31s 741us/step - loss: 0.5863 - acc: 0.8316 - val_loss: 1.3388 - val_acc: 0.5371\n",
            "Epoch 9/20\n",
            "42000/42000 [==============================] - 31s 739us/step - loss: 0.5612 - acc: 0.8372 - val_loss: 1.3447 - val_acc: 0.6068\n",
            "Epoch 10/20\n",
            "42000/42000 [==============================] - 31s 742us/step - loss: 0.5619 - acc: 0.8349 - val_loss: 1.1248 - val_acc: 0.6692\n",
            "Epoch 11/20\n",
            "42000/42000 [==============================] - 31s 741us/step - loss: 0.5122 - acc: 0.8493 - val_loss: 1.5865 - val_acc: 0.4488\n",
            "Epoch 12/20\n",
            "42000/42000 [==============================] - 31s 743us/step - loss: 0.5175 - acc: 0.8463 - val_loss: 1.4179 - val_acc: 0.5384\n",
            "Epoch 13/20\n",
            "42000/42000 [==============================] - 31s 743us/step - loss: 0.4921 - acc: 0.8529 - val_loss: 1.0507 - val_acc: 0.6951\n",
            "Epoch 14/20\n",
            "42000/42000 [==============================] - 31s 745us/step - loss: 0.4512 - acc: 0.8667 - val_loss: 0.9529 - val_acc: 0.7251\n",
            "Epoch 15/20\n",
            "42000/42000 [==============================] - 31s 745us/step - loss: 0.4307 - acc: 0.8714 - val_loss: 0.9917 - val_acc: 0.6978\n",
            "Epoch 16/20\n",
            "42000/42000 [==============================] - 32s 756us/step - loss: 0.4139 - acc: 0.8764 - val_loss: 0.9960 - val_acc: 0.7078\n",
            "Epoch 17/20\n",
            "42000/42000 [==============================] - 31s 745us/step - loss: 0.3898 - acc: 0.8834 - val_loss: 1.0345 - val_acc: 0.6794\n",
            "Epoch 18/20\n",
            "42000/42000 [==============================] - 31s 746us/step - loss: 0.3827 - acc: 0.8847 - val_loss: 1.1128 - val_acc: 0.6304\n",
            "Epoch 19/20\n",
            "42000/42000 [==============================] - 31s 745us/step - loss: 0.3840 - acc: 0.8837 - val_loss: 1.0932 - val_acc: 0.6314\n",
            "Epoch 20/20\n",
            "42000/42000 [==============================] - 31s 742us/step - loss: 0.3512 - acc: 0.8965 - val_loss: 1.0923 - val_acc: 0.6488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff45ef0ec18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0RKNClpV9zY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fdf2b30f-6e58-4aee-ff06-b6514e52f139"
      },
      "source": [
        "loss_and_metrics_2 = model_2.evaluate(x_test, y_test)\n",
        "print(loss_and_metrics_2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18000/18000 [==============================] - 5s 287us/step\n",
            "[1.0923315493265788, 0.6487777777777778]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}